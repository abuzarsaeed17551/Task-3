# Import libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc

# Load dataset (update path as needed)
df = pd.read_csv("heart.csv")  # Replace with your path if local

# Check for missing values
print("Missing values:\n", df.isnull().sum())

# Basic dataset info
print("\nDataset Info:")
print(df.info())
print("\nSummary Statistics:")
print(df.describe())

# EDA: Correlation heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Heatmap")
plt.show()

# Target distribution
sns.countplot(data=df, x='target')
plt.title("Heart Disease Presence (1 = Disease, 0 = No Disease)")
plt.show()

# Feature distributions by target
features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']
for feature in features:
    plt.figure(figsize=(6, 4))
    sns.boxplot(data=df, x='target', y=feature)
    plt.title(f"{feature} by Heart Disease")
    plt.show()

# Split dataset
X = df.drop('target', axis=1)
y = df['target']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train model (Logistic Regression or Decision Tree)
model = LogisticRegression(max_iter=1000)  # or use: model = DecisionTreeClassifier()
model.fit(X_train, y_train)

# Predictions and evaluation
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# ROC Curve
y_prob = model.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f"ROC Curve (AUC = {roc_auc:.2f})")
plt.plot([0, 1], [0, 1], 'k--')
plt.title("ROC Curve")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend(loc="lower right")
plt.show()

# Feature Importance
if isinstance(model, LogisticRegression):
    importance = model.coef_[0]
    features_importance = pd.Series(importance, index=X.columns)
else:  # DecisionTree
    importance = model.feature_importances_
    features_importance = pd.Series(importance, index=X.columns)

features_importance.sort_values(ascending=False).plot(kind='bar', figsize=(10, 6))
plt.title("Feature Importance")
plt.ylabel("Importance")
plt.tight_layout()
plt.show()
